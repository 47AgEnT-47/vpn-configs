name: vpn-checker
on:
  repository_dispatch:
    types: [vpn-checker]
  workflow_dispatch:           
jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Prepare Proxy List
        id: prepare
        run: |
          > temp.txt
          > seen_bodies.txt
          # --- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (50 –ø–æ—Ç–æ–∫–æ–≤) ---
          mkdir -p downloads
          rm -f downloads/* 2>/dev/null || true

          echo "üöÄ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤ 50 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤..."
          total_urls=$(wc -l < urls.txt)
          echo "üìä –í—Å–µ–≥–æ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: $total_urls"
          echo "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ..."

          awk '{print NR " " $0}' urls.txt | while read idx url; do
            [[ $url == http* ]] || continue
            echo "curl -sL --connect-timeout 5 --max-time 15 \"$url\" -o downloads/url_$idx.txt || true"
          done > download_jobs.txt

          if [ -s download_jobs.txt ]; then
            xargs -P 50 -I {} sh -c {} < download_jobs.txt 2>&1 | head -50 || true
          fi

          downloaded=$(ls downloads/url_*.txt 2>/dev/null | wc -l)
          echo "‚úÖ –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: $downloaded –∏–∑ $total_urls"
          rm -f download_jobs.txt

          # --- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (50 –ø–æ—Ç–æ–∫–æ–≤) ---
          echo "üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ 50 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö..."

          cat > process_proxy.py << 'EOF'
          import sys, base64, os

          protocols = ('vless://', 'vmess://', 'trojan://', 'hysteria', 'hysteria2', 'tuic')

          def main():
              source_file = sys.argv[1]
              url = sys.argv[2]
              part_id = sys.argv[3]
              
              try:
                  with open(source_file, 'r', encoding='utf-8') as f:
                      lines = f.readlines()
              except:
                  print(f'0 0 {url}')
                  return
              
              if len(lines) == 1 and lines[0].strip():
                  raw = lines[0].strip()
                  if not raw.lower().startswith(protocols):
                      try:
                          decoded = base64.b64decode(raw + '=' * (-len(raw) % 4)).decode('utf-8')
                          decoded_lines = [l.strip() for l in decoded.splitlines() if l.strip()]
                          if decoded_lines:
                              lines = decoded_lines
                      except:
                          pass
              
              found_in_url = 0
              temp_out = f'temp_{part_id}.txt'
              
              with open(temp_out, 'a', encoding='utf-8') as out:
                  for line in lines:
                      clean_line = line.strip()
                      if not clean_line or not clean_line.lower().startswith(protocols):
                          continue
                      found_in_url += 1
                      if '#' in clean_line:
                          body, remarks = clean_line.split('#', 1)
                      else:
                          body, remarks = clean_line, None
                      body_clean = ''.join(body.split())
                      final_line = f'{body_clean}#{remarks}' if remarks else body_clean
                      out.write(final_line + '\n')
              
              print(f'{found_in_url} {found_in_url} {url}')

          if __name__ == '__main__':
              main()
          EOF

          # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏ –¥–ª—è xargs
          for source_file in downloads/url_*.txt; do
            [ -f "$source_file" ] || continue
            [ -s "$source_file" ] || continue
            
            idx="${source_file#downloads/url_}"
            idx="${idx%.txt}"
            url=$(sed -n "${idx}p" urls.txt)
            
            echo "python3 process_proxy.py \"$source_file\" \"$url\" \"$idx\" || true"
          done > process_jobs.txt

          # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ 50 –ø–æ—Ç–æ–∫–æ–≤
          if [ -s process_jobs.txt ]; then
            xargs -P 50 -I {} sh -c {} < process_jobs.txt
          fi

          rm -f process_jobs.txt process_proxy.py

          # --- –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è ---
          echo "üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è..."
          
          > temp.txt
          > seen_bodies.txt
          
          TOTAL_FOUND=0
          TOTAL_ADDED=0
          
          for temp_file in temp_*.txt; do
            [ -f "$temp_file" ] || continue
            [ -s "$temp_file" ] || continue
            
            idx="${temp_file#temp_}"
            idx="${idx%.txt}"
            url=$(sed -n "${idx}p" urls.txt)
            
            found_in_url=$(wc -l < "$temp_file")
            TOTAL_FOUND=$((TOTAL_FOUND + found_in_url))
            
            added_from_url=0
            while IFS= read -r line; do
              if [ -n "$line" ]; then
                if [[ "$line" == *"#"* ]]; then
                  body="${line%#*}"
                else
                  body="$line"
                fi
                body_clean=$(echo "$body" | tr -d ' ')
                if ! grep -Fxq "$body_clean" seen_bodies.txt 2>/dev/null; then
                  echo "$body_clean" >> seen_bodies.txt
                  echo "$line" >> temp.txt
                  added_from_url=$((added_from_url + 1))
                fi
              fi
            done < "$temp_file"
            
            TOTAL_ADDED=$((TOTAL_ADDED + added_from_url))
            echo "üîó $url | –ù–∞–π–¥–µ–Ω–æ: $found_in_url | –î–æ–±–∞–≤–ª–µ–Ω–æ: $added_from_url"
            
            rm -f "$temp_file"
          done

          rm -rf downloads

          echo "=========================================="
          echo "‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: $TOTAL_FOUND"
          echo "‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–±–∞–≤–ª–µ–Ω–æ: $TOTAL_ADDED"
          echo "üëØ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ—Ç–±—Ä–æ—à–µ–Ω–æ: $((TOTAL_FOUND - TOTAL_ADDED))"
          echo "=========================================="

          TOTAL_LINES=$(wc -l < temp.txt 2>/dev/null || echo "0")
          echo "–ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: $TOTAL_LINES"

          MIN_LINES=1000
          MAX_FILES=10
          rm -f file_*.txt

          if [ "$TOTAL_LINES" -le "$MIN_LINES" ]; then
            cp temp.txt file_aa.txt
            echo "parts=aa" >> $GITHUB_OUTPUT
          else
            NUM_FILES=$(( (TOTAL_LINES + MIN_LINES - 1) / MIN_LINES ))
            if [ "$NUM_FILES" -gt "$MAX_FILES" ]; then NUM_FILES="$MAX_FILES"; fi
            split -n "l/$NUM_FILES" --additional-suffix=.txt temp.txt file_
            
            parts=()
            for f in file_*.txt; do
              if [ -s "$f" ]; then
                p="${f#file_}"
                p="${p%.txt}"
                parts+=("$p")
              fi
            done
            echo "parts=$(IFS=,; echo "${parts[*]}")" >> $GITHUB_OUTPUT
          fi

      - name: Set Matrix
        id: set-matrix
        run: |
          IFS=',' read -ra PARTS <<< "${{ steps.prepare.outputs.parts }}"
          MATRIX='{"part":['
          for i in "${!PARTS[@]}"; do
            if [ $i -gt 0 ]; then
              MATRIX+=","
            fi
            MATRIX+="\"${PARTS[$i]}\""
          done
          MATRIX+=']}'
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

      - name: Upload Parts
        uses: actions/upload-artifact@v4
        with:
          name: proxy-parts
          path: file_*.txt
          retention-days: 1

  check-proxies:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        part: ${{ fromJson(needs.prepare.outputs.matrix).part }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Part
        uses: actions/download-artifact@v4
        with:
          name: proxy-parts
          path: .

      - name: Download and Prepare xray-knife
        run: |
          curl -L "https://github.com/lilendian0x00/xray-knife/releases/download/v8.0.0/Xray-knife-linux-64.zip" -o xray-knife.zip
          unzip -o xray-knife.zip xray-knife
          chmod +x xray-knife

      - name: Run check
        run: |
          FILE="file_${{ matrix.part }}.txt"
          OUT="vless_${{ matrix.part }}.txt"
          
          echo "Working on $FILE"
          
          if [ -f "$FILE" ]; then
            ./xray-knife http -f "$FILE" -o "$OUT" -u http://google.com/generate_204 -z xray -e -d 10000 -t 300 < /dev/null || true
          else
            echo "Error: $FILE not found!"
          fi
          
          [ ! -f "$OUT" ] && touch "$OUT"
          echo "Resulting lines in $OUT: $(wc -l < $OUT)"

      - name: Upload Result
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.part }}
          path: "vless_*.txt"
          retention-days: 1

  merge-and-push:
    needs: check-proxies
    if: always()
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: results-*
          merge-multiple: true

      - name: Merge Results
        run: |
          grep -h -v '^$' vless_*.txt > configs.txt 2>/dev/null || touch configs.txt
          echo "Final count: $(wc -l < configs.txt)"

      - name: Push to Repository
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          git add configs.txt
          if ! git diff --staged --quiet; then
            git commit -m "Update proxies: $(date +'%Y-%m-%d %H:%M')"
            git pull --rebase origin main || git pull --rebase origin master
            git push origin HEAD
          fi

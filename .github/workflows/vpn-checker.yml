name: vpn-checker
on:
  repository_dispatch:
    #types: [vpn-checker]
  workflow_dispatch:           
jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Prepare Proxy List
        id: prepare
        run: |
          > temp.txt
          > seen_bodies.txt
          # --- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (50 –ø–æ—Ç–æ–∫–æ–≤) ---
          mkdir -p downloads
          rm -f downloads/* 2>/dev/null || true

          # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏ –¥–ª—è xargs: –∫–∞–∂–¥–∞—è –∫–æ–º–∞–Ω–¥–∞ curl —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª downloads/url_$idx.txt
          echo "üöÄ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤ 50 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤..."
          total_urls=$(wc -l < urls.txt)
          echo "üìä –í—Å–µ–≥–æ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: $total_urls"
          echo "‚è≥ –ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ..."

          awk '{print NR " " $0}' urls.txt | while read idx url; do
              [[ $url == http* ]] || continue
              echo "curl -sL --connect-timeout 5 --max-time 15 \"$url\" -o downloads/url_$idx.txt || true"
          done > download_jobs.txt

          if [ -s download_jobs.txt ]; then
              xargs -P 50 -I {} sh -c {} < download_jobs.txt 2>&1 | head -50 || true
          fi

          downloaded=$(ls downloads/url_*.txt 2>/dev/null | wc -l)
          echo "‚úÖ –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: $downloaded –∏–∑ $total_urls"
          rm download_jobs.txt  
          
          # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ) ---
          > temp.txt
          > seen_bodies.txt
          TOTAL_FOUND=0
          TOTAL_ADDED=0

          for source_file in downloads/url_*.txt; do
            [ -f "$source_file" ] || continue
            [ -s "$source_file" ] || continue

            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º URL –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–¥–ª—è –≤—ã–≤–æ–¥–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
            idx="${source_file#downloads/url_}"
            idx="${idx%.txt}"
            url=$(sed -n "${idx}p" urls.txt)

            # –í—ã–ø–æ–ª–Ω—è–µ–º Python‚Äë–æ–±—Ä–∞–±–æ—Ç–∫—É (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π base64, —Å–º. —Å–ª–µ–¥—É—é—â–∏–π –ø—É–Ω–∫—Ç)
            STATS=$(python3 -c "
          import sys, base64
          protocols = ('vless://', 'vmess://', 'trojan://', 'hysteria', 'hysteria2', 'tuic')
          url = sys.argv[1]
          try:
              with open('seen_bodies.txt', 'r') as f:
                  seen = set(line.strip() for line in f)
              with open('$source_file', 'r', encoding='utf-8') as f:
                  lines = f.readlines()
              # ---- –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ base64 (–≤–µ—Å—å —Ñ–∞–π–ª —Ü–µ–ª–∏–∫–æ–º) ----
              if len(lines) == 1 and lines[0].strip():
                  raw = lines[0].strip()
                  if not raw.lower().startswith(protocols):
                      try:
                          decoded = base64.b64decode(raw + '=' * (-len(raw) % 4)).decode('utf-8')
                          decoded_lines = [l.strip() for l in decoded.splitlines() if l.strip()]
                          if decoded_lines:
                              lines = decoded_lines
                      except:
                          pass

              found_in_url = 0
              added_from_url = 0
              with open('temp.txt', 'a', encoding='utf-8') as out, open('seen_bodies.txt', 'a', encoding='utf-8') as seen_file:
                  for line in lines:
                      clean_line = line.strip()
                      if not clean_line or not clean_line.lower().startswith(protocols):
                          continue
                      found_in_url += 1
                      if '#' in clean_line:
                          body, remarks = clean_line.split('#', 1)
                      else:
                          body, remarks = clean_line, None
                      body_clean = ''.join(body.split())
                      if body_clean not in seen:
                          seen.add(body_clean)
                          seen_file.write(body_clean + '\n')
                          final_line = f'{body_clean}#{remarks}' if remarks else body_clean
                          out.write(final_line + '\n')
                          added_from_url += 1
              print(f'{found_in_url} {added_from_url} {url}')
          except Exception as e:
              # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ ‚Äì –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤–µ—Å—å workflow, –≤—ã–≤–æ–¥–∏–º 0 0
              print(f'0 0 {url}')
          " "$url" || true)
          
            if [ -n "$STATS" ]; then
              READ_FOUND=$(echo $STATS | cut -d' ' -f1)
              READ_ADDED=$(echo $STATS | cut -d' ' -f2)
              READ_URL=$(echo $STATS | cut -d' ' -f3)
              TOTAL_FOUND=$((TOTAL_FOUND + READ_FOUND))
              TOTAL_ADDED=$((TOTAL_ADDED + READ_ADDED))
              echo "üîó $READ_URL | –ù–∞–π–¥–µ–Ω–æ: $READ_FOUND | –î–æ–±–∞–≤–ª–µ–Ω–æ: $READ_ADDED"
            fi
          done

            echo "=========================================="
            echo "‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: $TOTAL_FOUND"
            echo "‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–±–∞–≤–ª–µ–Ω–æ: $TOTAL_ADDED"
            echo "‚ùå –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ—Ç–±—Ä–æ—à–µ–Ω–æ: $((TOTAL_FOUND - TOTAL_ADDED))"
            echo "=========================================="
          
          rm -rf downloads
          TOTAL_LINES=$(wc -l < temp.txt 2>/dev/null || echo "0")
          echo "–ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: $TOTAL_LINES"


          MIN_LINES=1000
          MAX_FILES=20

          # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã, —á—Ç–æ–±—ã –Ω–µ —Å–º–µ—à–∞–ª–∏—Å—å
          rm -f file_*.txt

          if [ "$TOTAL_LINES" -le "$MIN_LINES" ]; then
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫ –º–∞–ª–æ ‚Äî –æ–¥–Ω–∞ —á–∞—Å—Ç—å
            cp temp.txt file_aa.txt
            echo "parts=aa" >> $GITHUB_OUTPUT
          else
            # –°—á–∏—Ç–∞–µ–º, –Ω–∞ —Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π –±–∏—Ç—å (–Ω–µ –±–æ–ª–µ–µ 10)
            NUM_FILES=$(( (TOTAL_LINES + MIN_LINES - 1) / MIN_LINES ))
            if [ "$NUM_FILES" -gt "$MAX_FILES" ]; then NUM_FILES="$MAX_FILES"; fi
    
            # –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: 
            # split -n l/10 —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ä–æ–≤–Ω–æ –Ω–∞ 10 —á–∞—Å—Ç–µ–π –ø–æ —Å—Ç—Ä–æ–∫–∞–º –±–µ–∑ –æ—Å—Ç–∞—Ç–∫–∞
            split -n "l/$NUM_FILES" --additional-suffix=.txt temp.txt file_
    
            parts=()
            for f in file_*.txt; do
              # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
              if [ -s "$f" ]; then
                p="${f#file_}"
                p="${p%.txt}"
                parts+=("$p")
              fi
            done
            echo "parts=$(IFS=,; echo "${parts[*]}")" >> $GITHUB_OUTPUT
          fi


          
      - name: Set Matrix
        id: set-matrix
        run: |
          # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É
          IFS=',' read -ra PARTS <<< "${{ steps.prepare.outputs.parts }}"
          MATRIX='{"part":['
          for i in "${!PARTS[@]}"; do
            if [ $i -gt 0 ]; then
              MATRIX+=","
            fi
            MATRIX+="\"${PARTS[$i]}\""
          done
          MATRIX+=']}'
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

      - name: Upload Parts
        uses: actions/upload-artifact@v4
        with:
          name: proxy-parts
          path: file_*.txt
          retention-days: 1

  check-proxies:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        part: ${{ fromJson(needs.prepare.outputs.matrix).part }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Part
        uses: actions/download-artifact@v4
        with:
          name: proxy-parts
          path: .

      - name: Download and Prepare xray-knife
        run: |
          curl -L "https://github.com/lilendian0x00/xray-knife/releases/download/v8.0.0/Xray-knife-linux-64.zip" -o xray-knife.zip
          unzip -o xray-knife.zip xray-knife
          chmod +x xray-knife

      - name: Run check
        run: |
          FILE="file_${{ matrix.part }}.txt"
          OUT="vless_${{ matrix.part }}.txt"
          
          echo "Working on $FILE"
          
          if [ -f "$FILE" ]; then
            ./xray-knife http -f "$FILE" -o "$OUT" -u http://google.com/generate_204 -z xray -e -d 10000 -t 300 < /dev/null || true
          else
            echo "Error: $FILE not found!"
          fi
          
          [ ! -f "$OUT" ] && touch "$OUT"
          echo "Resulting lines in $OUT: $(wc -l < $OUT)"

      - name: Upload Result
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.part }}
          path: "vless_*.txt"
          retention-days: 1

  merge-and-push:
    needs: check-proxies
    if: always()
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: results-*
          merge-multiple: true

      - name: Merge Results
        run: |
          grep -h -v '^$' vless_*.txt > configs.txt 2>/dev/null || touch configs.txt
          echo "Final count: $(wc -l < configs.txt)"

      - name: Push to Repository
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          git add configs.txt
          if ! git diff --staged --quiet; then
            git commit -m "Update proxies: $(date +'%Y-%m-%d %H:%M')"
            git pull --rebase origin main || git pull --rebase origin master
            git push origin HEAD
          fi
